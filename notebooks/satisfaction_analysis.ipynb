{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engagement score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Bearer Id  engagement_score\n",
      "0  6.917538e+18          0.983794\n",
      "1  6.917538e+18          1.160657\n",
      "2  6.917538e+18          1.345800\n",
      "3  6.917538e+18          1.440488\n",
      "4  6.917538e+18          1.016334\n",
      "Engagement scores have been saved to ../assets/data/engagement_scores.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function engagement_score.calculate_engagement_score(input_file, output_file)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "sys.path.append('../scripts')  \n",
    "from engagement_score import calculate_engagement_score\n",
    "\n",
    "# Define paths\n",
    "input_file = '../assets/data/aggregated_xdr_data.csv'\n",
    "output_file = \"../assets/data/engagement_scores.csv\"      \n",
    "\n",
    "# Call the engagement function\n",
    "calculate_engagement_score(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experience score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience scores saved to ../assets/data/user_data_with_experience_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')  \n",
    "from experience_score import load_user_data, calculate_experience_score, save_data_with_scores\n",
    "\n",
    "import numpy as np\n",
    "centroid_cluster_1 = np.array([2.064230e+07, 65.010918, 1372.051897])\n",
    "\n",
    "\n",
    "user_data_path = '../assets/data/aggregated_xdr_data.csv'  \n",
    "user_data = load_user_data(user_data_path)\n",
    "\n",
    "\n",
    "user_data_with_scores = calculate_experience_score(user_data, centroid_cluster_1)\n",
    "\n",
    "\n",
    "output_path = '../assets/data/user_data_with_experience_scores.csv'  \n",
    "\n",
    "# Save the data with experience scores to the output path\n",
    "save_data_with_scores(user_data_with_scores, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combining the experience and enagement score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Bearer Id  engagement_score  Number_of_Sessions  \\\n",
      "0       6.917538e+18          0.983794                   1   \n",
      "1       6.917538e+18          1.160657                   1   \n",
      "2       6.917538e+18          1.345800                   1   \n",
      "3       6.917538e+18          1.440488                   1   \n",
      "4       6.917538e+18          1.016334                   1   \n",
      "...              ...               ...                 ...   \n",
      "134703  1.318654e+19          1.300365                   1   \n",
      "134704  1.318654e+19          0.625165                   1   \n",
      "134705  1.318654e+19          1.164043                   1   \n",
      "134706  1.318654e+19          0.623930                   1   \n",
      "134707  1.318654e+19          0.699664                   1   \n",
      "\n",
      "        Total_Session_Duration  Total_Download  Total_Upload  \\\n",
      "0                      24534.0     500721999.0    41704610.0   \n",
      "1                      21489.0     709549265.0    38693596.0   \n",
      "2                      27786.0     854465860.0    15548926.0   \n",
      "3                      15635.0     825786510.0    49605688.0   \n",
      "4                      24264.0     624957763.0    21983463.0   \n",
      "...                        ...             ...           ...   \n",
      "134703                 80024.0     145293140.0    35412664.0   \n",
      "134704                145291.0     387001634.0    36189587.0   \n",
      "134705                 86399.0     872688792.0    35919460.0   \n",
      "134706                 86399.0     386355068.0    40877676.0   \n",
      "134707                103113.0     327212841.0    46147558.0   \n",
      "\n",
      "        Total_Data_Volume  experience_score  \n",
      "0             542426609.0      2.064230e+07  \n",
      "1             748242861.0      2.064230e+07  \n",
      "2             870014786.0      2.064230e+07  \n",
      "3             875392198.0      2.064230e+07  \n",
      "4             646941226.0      2.064230e+07  \n",
      "...                   ...               ...  \n",
      "134703        180705804.0      2.064230e+07  \n",
      "134704        423191221.0      2.064230e+07  \n",
      "134705        908608252.0      2.064230e+07  \n",
      "134706        427232744.0      2.064230e+07  \n",
      "134707        373360399.0      2.064230e+07  \n",
      "\n",
      "[134708 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths for the two datasets\n",
    "file_path_1 = '../assets/data/engagement_scores.csv'\n",
    "file_path_2 = '../assets/data/user_data_with_experience_scores.csv'\n",
    "\n",
    "# Load the datasets from CSV files\n",
    "df1 = pd.read_csv(file_path_1)\n",
    "df2 = pd.read_csv(file_path_2)\n",
    "\n",
    "# Merge the datasets on 'Bearer Id'\n",
    "merged_df = pd.merge(df1, df2, on='Bearer Id', how='inner')\n",
    "\n",
    "# Save the merged dataset to a new CSV file\n",
    "merged_df.to_csv('../assets/data/merged_dataset.csv', index=False)\n",
    "\n",
    "# Display the merged dataset\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satisfaction score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Satisfied Customers:\n",
      "           Bearer Id  satisfaction_score\n",
      "103378  1.304243e+19        1.032117e+07\n",
      "97305   1.304243e+19        1.032116e+07\n",
      "37995   7.349883e+18        1.032116e+07\n",
      "88125   1.304243e+19        1.032116e+07\n",
      "88030   1.304243e+19        1.032116e+07\n",
      "93908   1.304243e+19        1.032116e+07\n",
      "86526   1.304243e+19        1.032116e+07\n",
      "119186  1.311448e+19        1.032116e+07\n",
      "82371   1.304243e+19        1.032116e+07\n",
      "88183   1.304243e+19        1.032116e+07\n",
      "Top 10 satisfied customers have been saved to ../assets/data/10_satisfaction.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function satisfaction_score.calculate_satisfaction_score(input_file, output_file, top_10_output_file)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')  \n",
    "from satisfaction_score import calculate_satisfaction_score\n",
    "\n",
    "input_file = '../assets/data/merged_dataset.csv'  \n",
    "output_file = '../assets/data/satisfaction_score.csv' \n",
    "top_10_output_file = '../assets/data/10_satisfaction.csv'\n",
    "\n",
    "\n",
    "calculate_satisfaction_score(input_file, output_file,top_10_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model for Satisfaction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "Mean Squared Error (MSE): 0.10624286797664897\n",
      "Mean Absolute Error (MAE): 0.22933701079152954\n",
      "R^2 Score: 0.4893930611334242\n",
      "Trained model saved to ../assets/data/model.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_satisfaction_model(input_file, output_model_file):\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(input_file)\n",
    "    \n",
    "    # Ensure the dataset contains the necessary columns\n",
    "    required_columns = ['engagement_score', 'experience_score', 'Number_of_Sessions', \n",
    "                        'Total_Session_Duration', 'Total_Data_Volume', 'satisfaction_score']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"The dataset must contain the following columns: {required_columns}\")\n",
    "    \n",
    "    # Select features (X) and target (y)\n",
    "    X = data[['engagement_score', 'experience_score', 'Number_of_Sessions', \n",
    "              'Total_Session_Duration', 'Total_Data_Volume']]\n",
    "    y = data['satisfaction_score']\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model Evaluation Metrics:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    import joblib\n",
    "    joblib.dump(model, output_model_file)\n",
    "    print(f\"Trained model saved to {output_model_file}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "input_file = '../assets/data/satisfaction_score.csv'  # Replace with the path to your input CSV file\n",
    "output_model_file = '../assets/data/model.joblib'  # Replace with the desired model output file path\n",
    "\n",
    "trained_model = train_satisfaction_model(input_file, output_model_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
